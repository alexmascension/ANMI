{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alexmascension/ANMI/blob/main/notebook/T6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vf3GioQwcepr"
   },
   "source": [
    "# Tema 6: Derivación e integración numérica\n",
    "\n",
    "Este tema lo construyo en parte basado en https://brianheinold.net/notes/An_Intuitive_Guide_to_Numerical_Methods_Heinold.pdf, que proporciona un enfoque bastante más práctico del tema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hDZNaYFX936"
   },
   "outputs": [],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/alexmascension/ANMI/main/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYo_JGn2TSxC"
   },
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "from sympy.matrices import Matrix as mat\n",
    "from sympy.matrices import randMatrix\n",
    "from sympy import symbols\n",
    "import sympy\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.linalg import orth\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anmi.T5 import polinomio_newton, roots_chebyshev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-V6kF8_X937"
   },
   "outputs": [],
   "source": [
    "from anmi.genericas import norma_p_func, norma_inf_func, matriz_inversa\n",
    "from anmi.T5 import polinomio_lagrange, polinomio_newton, error_lagrange, error_maximo_estocastico, roots_chebyshev\n",
    "from anmi.T5 import aitken_neville, interpolacion_hermite, polinomio_generico, esplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z, a, lambda_, h = symbols('x'), symbols('y'), symbols('z'), symbols('a'), symbols('lambda'), symbols('h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivación numérica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El problema de la aritmética finita en el cálculo de derivadas\n",
    "\n",
    "El problema principal del cálculo de derivadas está en que el denominador de la derivada se hace muy pequeño:\n",
    "$f'(x) = \\frac{f(x+h) - f(x)}{h}$\n",
    "\n",
    "En ese sentido, si empezamos a usar valores de $h$ muy pequeños, podemos acabar teniendo valores de derivada alejados de la realidad. Como ejemplo, vamos a evaluar la derivada de $2x$ en $x=3$, empleando diferentes valores de $h$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(23):\n",
    "    print(n, (((x+h) ** 2 - x**2) / (h)).subs(h, 10**(-n)).subs(x, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que para valores de h de $10^{-13}$ para abajo, las derivadas se nos van de madre. Esto es problemático porque para derivadas más complejas el error aumenta y no nos podremos fiar directamente de los resultados. Para mitigar estos problemas en estas secciones trabajaremos con diferentes métodos de aproximación de derivadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fórmulas de derivación numérica\n",
    "En esta sección vamos a derivar diferentes métodos de cálculo de derivadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando el polinomio de Newton\n",
    "Una de las opciones para calcular la derivada $n$-ésima es generar un polinomio de grado $n$ y aplicar su derivada $n$ veces. Para ello podemos emplear el método de Newton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(polinomio_newton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(derivacion_polinomio_newton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivacion_polinomio_newton(f, x0, var=symbols('x'), grado=1, h=0.01):\n",
    "    x_vals = [x0 + i * h for i in range(grado + 1)]\n",
    "    y_vals = [f.subs(var, (x0 + i * h)) for i in range(grado + 1)]\n",
    "    \n",
    "    # Con esto creamos el polinomio\n",
    "    p, m = polinomio_newton(x_vals, y_vals, var)\n",
    "    \n",
    "    # Ahora lo diferenciamos\n",
    "    p_diff = p\n",
    "    for i in range(grado):\n",
    "        p_diff = p_diff.diff(var)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return p_diff, p, m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EJEMPLO 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_diff, p, m =  derivacion_polinomio_newton(f=sqrt(x), x0=1, var=symbols('x'), grado=3, h=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expand(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N(p_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a jugar con otros valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_diff, p, m =  derivacion_polinomio_newton(f=sqrt(x), x0=1, var=symbols('x'), grado=3, h=0.01)\n",
    "N(p_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_diff, p, m =  derivacion_polinomio_newton(f=sqrt(x), x0=1, var=symbols('x'), grado=3, h=0.001)\n",
    "N(p_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_diff, p, m =  derivacion_polinomio_newton(f=sqrt(x), x0=1, var=symbols('x'), grado=3, h=0.0001)\n",
    "N(p_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que con $h$ más pequeños, el valor se asemeja más al verdadero de 0.375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_diff, p, m =  derivacion_polinomio_newton(f=sqrt(x), x0=1, var=symbols('x'), grado=3, h=0.0000001)\n",
    "N(p_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_diff, p, m =  derivacion_polinomio_newton(f=sqrt(x), x0=1, var=symbols('x'), grado=3, h=0.000000001)\n",
    "N(p_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, como antes, si tomamos $h$ extremadamente pequeños, el cálculo se nos va de madre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo de error en derivadas\n",
    "Muchas veces nos interesa poder hallar el error de aproximación de la derivada, para ver hasta qué punto nos parece una aproximación adecuada.\n",
    "Recordemos que la expansión de Taylor de $f(x)$ en $x=a$ es:\n",
    "$$f(x) = f(a) + f'(a)(x-a) + \\frac{f^{(2)}(a)}{2!}(x-a)^2 + \\frac{f^{(3)}(a)}{3!}(x-a)^3 + \\cdots$$\n",
    "Si sustituimos $x$ for $x+h$ y tomando $a$ como $x-h$, la fórmula anterior queda como:\n",
    "$$f(x+h) = f(x) + f'(x)h + \\frac{f^{(2)}(x)}{2!}h^2 + \\frac{f^{(3)}(x)}{3!}h^3 + \\cdots$$\n",
    "Resolviendo para $f'(x)$ tenemos:\n",
    "$$ f'(x) = \\frac{f(x+h) - f(x)}{h} - \\frac{f^{(2)}(x)}{2!}h - \\frac{f^{(3)}(x)}{3!}h^2 - \\cdots$$\n",
    "\n",
    "Luego el error de aproximación pertenecería a los términos de derivada segunda y superiores. Para simplificar, nos quedamos solo con el término de derivada segunda y se cumple que, para un $c \\in [x, x+h]$\n",
    "$$f'(x) = \\frac{f(x+h) - f(x)}{h} - \\frac{f^{(2)}(c)}{2!}h$$\n",
    "De modo que podemos acotar el error.\n",
    "\n",
    "Esta estrategia de cálculo de error la emplearemos después en otros métodos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivación con polinomios de Lagrange\n",
    "Otro método es construyendo polinomios de Lagrange. Recordemos que los polinomios vienen dados por la fórmula:\n",
    "$$p_n(x) = \\sum_{i=0}^n l_i(x)f(x_i)$$\n",
    "Si aplicamos una derivación a $p_n(x)$ en $\\bar{x}_0$ obtenemos el siguiente polinomio:\n",
    "$$D(f)(\\bar{x_0}) = \\sum_{i = 0}^n l'_i(\\bar{x}_0)f(x_i)$$\n",
    "$\\bar{x_0}$ es un punto cualquiera del intervalo, y puede o no coincidir con alguno de los nodos.\n",
    "\n",
    "Recordemos que la construcción de $p(x)$ viene dada por la base $\\{1, x, \\cdots, x^n\\}$ y cada termino es $x^j = \\sum_{i=0}^n l_i(x)x^j$, de modo que, matricialmente, $p(x)$ se construye como:\n",
    "$$\\begin{bmatrix}\n",
    "1 & 1 & \\cdots & 1 \\\\\n",
    "x_0 & x_1 & \\cdots & x_n\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "x_0^n & x_1^n & \\cdots & x_n^n\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "l_0\\\\\n",
    "l_1\\\\\n",
    "\\vdots\\\\\n",
    "l_n\\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "1\\\\\n",
    "x\\\\\n",
    "\\vdots\\\\\n",
    "x^n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Si derivamos $r$ veces en $\\bar{x}_0$, acabamos con el sistema:\n",
    "$$\\begin{bmatrix}\n",
    "1 & 1 & \\cdots & 1 \\\\\n",
    "x_0 & x_1 & \\cdots & x_n\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "x_0^n & x_1^n & \\cdots & x_n^n\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "l^{(r)}_0=a_0\\\\\n",
    "l^{(r)}_1=a_1\\\\\n",
    "\\vdots\\\\\n",
    "l^{(r)}_n=a_n\\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "0\\\\\n",
    "0\\\\\n",
    "\\vdots\\\\\n",
    "(n)(n-1)\\cdots(n-r)\\bar{x}_0^{n-r}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(polinomio_lagrange_derivada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: implementar la función de error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polinomio_lagrange_derivada(f, x0, x_vals=None, var=symbols('x'), grado=1, I=[0, 1]):\n",
    "    ff = Function('f')\n",
    "    \n",
    "    if x_vals is None:\n",
    "        x_vals = np.linspace(I[0], I[1], grado + 1)\n",
    "    assert len(x_vals) == grado + 1\n",
    "    \n",
    "    G = ones(len(x_vals), len(x_vals))\n",
    "    for row in range(1, len(x_vals)):\n",
    "        for col in range(len(x_vals)):\n",
    "            G[row, col] = x_vals[col] ** row\n",
    "            \n",
    "    x_mat = Matrix([var ** i for i in range(grado + 1)])\n",
    "    for _ in range(grado):\n",
    "        x_mat = x_mat.diff(var)\n",
    "    \n",
    "    # Con esto creamos el vector de valores de A\n",
    "    a = matriz_inversa(G) * x_mat\n",
    "    \n",
    "    p, val = S(0), S(0)\n",
    "    for i in range(grado + 1):\n",
    "        p += a[i] * ff(x_vals[i])\n",
    "        val += a[i] * f.subs(var, x_vals[i])\n",
    "    \n",
    "    return p, val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomio_lagrange_derivada(f=x**3, x0=2, x_vals=[1, 2, 3], var=symbols('x'), grado=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de extrapolación de Richardson\n",
    "Para explicar el método me voy a basar en la explicación de Wikipedia, que generaliza mejor, con cambios de notación. https://en.wikipedia.org/wiki/Richardson_extrapolation\n",
    "\n",
    "Supongamos que tenemos una función $N(h)$, que la empleamos como aproximación a la derivada en $h=0$, $N(0)$. La función $N(h)$ va a tener una expansión del error del siguiente modo:\n",
    "$$N(h) = N(0) + a_0h^{k_0} + a_1h^{k_1} + a_2h^{k_2} + \\cdots$$\n",
    "\n",
    "En primer lugar, tomamos un parametro $r$, de modo que podemos sustituir $h$ por $rh$ del siguiente modo:\n",
    "$$N(rh) = N(0) + a_0(rh)^{k_0} + a_1(rh)^{k_1} + a_2(rh)^{k_2} + \\cdots$$\n",
    "\n",
    "Si multiplicamos por $(r)^{k_0}$ y restamos tenemos que:\n",
    "$$r^{k_0}N(h) =  N(0) + a_0r^{k_0}h^{k_0} + a_1r^{k_0}h^{k_1} + a_2r^{k_0}h^{k_2} + \\cdots$$\n",
    "\n",
    "$$r^{k_0}N(h) -  N(rh)=  N(0) + (r^{k_0} - r^{k_1})a_1h^{k_1} + (r^{k_0} - r^{k_2})a_2h^{k_2} + \\cdots$$\n",
    "\n",
    "Luego\n",
    "$$N_1(h) = \\frac{r^{k_0}N(h) -  N(rh)}{r^{k_0} - 1}= N(0) + \\frac{r^{k_0} - r^{k_1}}{r^{k_0} - 1}a_1h^{k_1} + \\frac{r^{k_0} - r^{k_2}}{r^{k_0} - 1}a_2h^{k_2} + \\cdots$$\n",
    "\n",
    "Vemos que ahora tenemos una nueva función, $N_1(h)$, que depende de $a_1h^{k_1} + a_2h^{k_2} + \\cdots$, luego hemos reducido su error, ya que $\\frac{r^{k_0} - r^{k_1}}{r^{k_0} - 1}$ tiene menos influencia que el orden de $h$. Con iteraciones sucesivas podemos hacer este error tan pequeño como veamos, dentro de la capacidad de error aritmética de $r^nh$ para el ordenador.\n",
    "\n",
    "Generalizando, la fórmula final es:\n",
    "$$N_a(r^bh) = \\frac{r^{m+a-1}N(r^bh) - N(r^{b+1}h)}{r^{m+a-1} - 1}$$\n",
    "\n",
    "El valor $m=k_0$ depende de $N(h)$. Si, por ejemplo, $N(h) = \\frac{f(x+h) - f(x-h)}{2h}$, considerando los desarrollos de Taylor:\n",
    "$$f(x+h) = f(x) + f'(x)fh + \\frac{1}{2}f''(x)h^2 + \\frac{1}{3!}f'''(x)h^3 + \\frac{1}{4!}f''''(x)h^4 + \\cdots$$\n",
    "$$f(x-h) = f(x) - f'(x)fh + \\frac{1}{2}f''(x)h^2 - \\frac{1}{3!}f'''(x)h^3 + \\frac{1}{4!}f''''(x)h^4 + \\cdots$$\n",
    "\n",
    "Se tiene que $N(h) = f'(x) + \\frac{h^2}{3!}f'''(x) + \\frac{h^4}{5!}f^{(5)}(x) +\\cdots$, luego $m=2$\n",
    "\n",
    "Para simplificar los cálulos, se hace un cálculo tabular de todas estas sucesiones. Para ello se hacen los cálculos de la siguiente manera:\n",
    "$$\n",
    "\\begin{matrix}\n",
    "h & N(h) & N_1(h) & N_2(h) & N_3(h) \\\\\n",
    "rh & N(rh) & N_1(rh) & N_2(rh) & \\cdots \\\\\n",
    "r^2h & N(r^2h) & N_1(r^2h) & \\cdots & \\cdots \\\\\n",
    "r^3h & N(r^3h) & \\cdots & \\cdots & \\cdots \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\ddots \\\\\n",
    "\\end{matrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivada_richardson(f, x0=0, r=0.5, h=0.5, x_var=symbols('x'), h_var=symbols('h'), Nf=None, m=None, grado=3):\n",
    "    if Nf is None:\n",
    "        Nf = (f.subs(x_var, x0 + h_var) - f.subs(x_var, x0 - h_var))/(2 * h_var)\n",
    "        m = 2\n",
    "        \n",
    "    matriz_r = zeros(grado, grado)\n",
    "    \n",
    "    # primero llenamos la matriz con los valores N(rih)\n",
    "    for row in range(grado):\n",
    "        rih = r ** row * h\n",
    "        matriz_r[row, 0] = nsimplify(Nf.subs(h_var, rih),tolerance=1e-10,rational=True)\n",
    "        \n",
    "    for col in range(1, grado):\n",
    "        for row in range(grado - col):\n",
    "            r_exp = m + col - 1\n",
    "            matriz_r[row, col] = nsimplify((r**r_exp * matriz_r[row, col - 1] - matriz_r[row+1, col - 1])/(r**r_exp - 1), rational=True)\n",
    "            \n",
    "    \n",
    "    return Nf, matriz_r\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EJERCICIO 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = sin(2*pi*x)\n",
    "x0, r, h = 0, 0.5, 0.5\n",
    "\n",
    "Nf, matriz_r = derivada_richardson(f=f, x0=x0, r=r, h=h, grado=3)\n",
    "Nf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EJEMPLO de HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = -cos(x)\n",
    "x0, r, h = 1, 0.5, 1\n",
    "\n",
    "Nf, matriz_r = derivada_richardson(f=f, x0=x0, r=r, h=h, grado=6)\n",
    "N(matriz_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integración numérica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuadratura basada en la interporlación\n",
    "\n",
    "El método de cuadratura basado en intepolación está basado en el polinomio de Legendre. La metodología es la misma que para la derivada, solo que sustituyendo la derivada con la integral.\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "1 & 1 & \\cdots & 1 \\\\\n",
    "x_0 & x_1 & \\cdots & x_n\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "x_0^n & x_1^n & \\cdots & x_n^n\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "l^{(r)}_0=a_0\\\\\n",
    "l^{(r)}_1=a_1\\\\\n",
    "\\vdots\\\\\n",
    "l^{(r)}_n=a_n\\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "\\int_a^b 1 dx = b-a\\\\\n",
    "\\int_a^b x dx =  \\frac{b^2-a^2}{2}\\\\\n",
    "\\vdots\\\\\n",
    "\\int_a^b x^n dx =  \\frac{b^{n+1}-a^{n+1}}{n+1}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Para el método de newton, el sistema de matrices a resolver es:\n",
    "$$\\begin{bmatrix}\n",
    "1 & 1 & \\cdots & 1 \\\\\n",
    "0 & \\omega_1(x_1) & \\cdots & \\omega_1(x_n)\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "0 & 0 & \\cdots & \\omega_n(x_n)\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "l_0\\\\\n",
    "l_1\\\\\n",
    "\\vdots\\\\\n",
    "l_n\\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "1\\\\\n",
    "\\omega_1\\\\\n",
    "\\vdots\\\\\n",
    "\\omega_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Donde $\\omega_i(x) = (x-x_0)(x-x_1)\\cdots(x-x_{i-1})$\n",
    "\n",
    "Si integramos el rhs tenemos el sistema:\n",
    "$$\\begin{bmatrix}\n",
    "1 & 1 & \\cdots & 1 \\\\\n",
    "0 & \\omega_1(x_1) & \\cdots & \\omega_1(x_n)\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "0 & 0 & \\cdots & \\omega_n(x_n)\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "l_0\\\\\n",
    "l_1\\\\\n",
    "\\vdots\\\\\n",
    "l_n\\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "\\int_a^b dx\\\\\n",
    "\\int_a^b \\omega_1(x) dx\\\\\n",
    "\\vdots\\\\\n",
    "\\int_a^b \\omega_n(x) dx\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(polinomio_lagrange_integracion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: implementar la función de error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polinomio_lagrange_integracion(f=x, x0=None, x_vals=None, grado=3, var=symbols('x'), I=[0, 1]):\n",
    "    ff = Function('f')\n",
    "    \n",
    "    if x_vals is None:\n",
    "        x_vals = np.linspace(I[0], I[1], grado)\n",
    "    \n",
    "    G = ones(len(x_vals), len(x_vals))\n",
    "    for row in range(1, len(x_vals)):\n",
    "        for col in range(len(x_vals)):\n",
    "            G[row, col] = x_vals[col] ** row\n",
    "            \n",
    "    x_mat = nsimplify(Matrix([(I[1] ** (i + 1) - I[0] ** (i + 1))/(i + 1) for i in range(len(x_vals))]), rational=True)\n",
    "\n",
    "    # Con esto creamos el vector de valores de A\n",
    "    a = nsimplify(matriz_inversa(G) * x_mat, rational=True)\n",
    "    \n",
    "    p, val = S(0), S(0)\n",
    "    for i in range(len(x_vals)):\n",
    "        p += a[i] * ff(x_vals[i])\n",
    "        val += a[i] * f.subs(var, x_vals[i])\n",
    "    \n",
    "    return p, val\n",
    "\n",
    "def polinomio_newton_integracion(f=x, x0=None, x_vals=None, grado=3, var=symbols('x'), I=[0, 1]):\n",
    "    ff = Function('f')\n",
    "    \n",
    "    if x_vals is None:\n",
    "        x_vals = np.linspace(I[0], I[1], grado)\n",
    "    \n",
    "    # Creamos la lista de omegas, que tienen la expresión [w_1, w_2, w_3, etc]\n",
    "    lista_w = [1, (var - x_vals[0])]\n",
    "    for x_val in x_vals[1:]:\n",
    "        lista_w.append(lista_w[-1] * (var - x_val))\n",
    "    \n",
    "    G = zeros(len(x_vals), len(x_vals))\n",
    "    x_mat = zeros(len(x_vals), 1)\n",
    "    for row in range(len(x_vals)):\n",
    "        for col in range(row, len(x_vals)):\n",
    "            if row == 0:\n",
    "                G[row, col] = 1\n",
    "            else:\n",
    "                G[row, col] = lista_w[row].subs(var, x_vals[col])\n",
    "    \n",
    "        x_mat[row, 0] = integrate(lista_w[row], (x, I[0], I[1]))\n",
    "    \n",
    "    # Con esto creamos el vector de valores de A\n",
    "    a = matriz_inversa(G) * x_mat\n",
    "    \n",
    "    p, val = S(0), S(0)\n",
    "    for i in range(len(x_vals)):\n",
    "        p += a[i] * ff(x_vals[i])\n",
    "        val += a[i] * f.subs(var, x_vals[i])\n",
    "    \n",
    "    return p, val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EJERCICIO 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, v = polinomio_lagrange_integracion(x_vals=[1, 2, 3], I=[0, 4])\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, v = polinomio_newton_integracion(x_vals=[1, 2, 3], I=[0, 4])\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EJERCICIO 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, v = polinomio_lagrange_integracion(x_vals=roots_chebyshev(2, I=[-1, 1]), I=[-1, 1])\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimación del error de cuadratura\n",
    "\n",
    "El error de cuadratura viene definido como \n",
    "$$e=\\int_a^bf(x)dx - Q(f)$$\n",
    "\n",
    "Y se tiene que\n",
    "$$|e| \\le \\frac{\\max_{\\xi \\in [a,b]} f^{(n+1)}(\\xi)}{(n+1)!} \\int_a^b|\\omega_{n+1}(x)| $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integral_positiva_newton(omega, I, var, x_vals):\n",
    "    # Esta función la creo para que calcule la integral del valor absoluto. Como las integrales son de la forma (x-x0)(x-x1)(x-x2)(x-x3)...\n",
    "    # con xi diferentes y en orden creciente, la función va a tomar un valor negativo si el número de términos es impar, y positivo si par\n",
    "    # para a < x_0, y de ahí va a ir alternando signos. Como pueden surgir casos diferentes (que I[0] sea x_vals[0]) y la casuistica cambia\n",
    "    # para cada x_i, x_i+1 tomaremos la integral y evaluaremos el signo, para ponerlo a la integral de nuevo.\n",
    "    integral = S(0)\n",
    "    \n",
    "    x_vals_I = [I[0]] + x_vals + [I[1]]\n",
    "    for i in range(len(x_vals_I) - 1):\n",
    "        a, b = x_vals_I[i], x_vals_I[i+1]\n",
    "        integral_i = Integral(omega, (var, a, b)).doit()\n",
    "        \n",
    "        if integral_i > 0:\n",
    "            signo = 1\n",
    "        elif integral_i < 0:\n",
    "            signo = -1\n",
    "        else: # a = b y la integral es cero\n",
    "            continue\n",
    "        integral += signo * integral_i\n",
    "    \n",
    "    return integral\n",
    "        \n",
    "def error_cuadratura_integral(f, var=symbols('x'), x_vals=None, I=[0,1], grado=2):\n",
    "    if x_vals is None:\n",
    "        x_vals = np.linspace(I[0], I[1], grado)\n",
    "    \n",
    "    # Hallamos el primer término, el del máximo de la derivada\n",
    "    diff_f = f\n",
    "    for _ in range(len(x_vals)):\n",
    "        diff_f = diff_f.diff(var)\n",
    "\n",
    "    max_diff_f = nsimplify(maximum(diff_f, var, Interval(I[0], I[1])) / factorial(len(x_vals)), rational=True)\n",
    "    \n",
    "    # Ahora hallamos el de la integral\n",
    "    omega = S(1)\n",
    "    for x_val in x_vals:\n",
    "        omega *= (var - x_val)\n",
    "    \n",
    "    int_omega = nsimplify(integral_positiva_newton(omega, I, var, x_vals), rational=True)\n",
    "    \n",
    "    e = max_diff_f * int_omega\n",
    "    \n",
    "    return e, max_diff_f, int_omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### EJERCICIO 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e, max_diff_f, int_omega = error_cuadratura_integral(f=sin(pi*x), x_vals=roots_chebyshev(2, I=[-1, 1]), I=[-1, 1])\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fórmulas cerradas de Newton-Cotes\n",
    "\n",
    "Una de las maneras de aproximar la integral de una función es dividirla en $n$ nodos y aproximar la integral mediante una función de tipo $\\int_a^bf(x)dx \\sim A_0f(a=x_0) + A_1f(x_1) + A_2f(x_2) + \\cdots + A_nf(x_n)$.\n",
    "\n",
    "Según el grado del polinomio de aproximación que queramos, tenemos las siguientes fórmulas:\n",
    "* grado 0 (extremo izquierdo): $\\int_a^b f(x) dx \\sim (b-a)f(a)$\n",
    "* grado 1 (trapecios): $\\int_a^b f(x) dx \\sim \\frac{b-a}{2}(f(a) + f(b))$\n",
    "* grado 2 (Simpson): $\\int_a^b f(x) dx \\sim \\frac{b-a}{6}(f(a) + 4f(\\frac{a+b}{2}) + f(b))$\n",
    "\n",
    "Que, quitando parafernalia, buscan una manera de aproximar con polinomios de diferentes grados la función entre $a$ y $b$. Obviamente, si la función es complicada, la aproximación no va a ser tan buena, pero para ello veremos métodos de como aplicarlo por partes.\n",
    "\n",
    "![irudia.png](../img/newton_cotes.png)\n",
    "\n",
    "¿Y cómo se puede hallar la aproximación para grado $n$? Para ello empleamos la cuadratura basada en la interpolación, que hemos visto antes:\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "1 & 1 & \\cdots & 1 \\\\\n",
    "x_0 & x_1 & \\cdots & x_n\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "x_0^n & x_1^n & \\cdots & x_n^n\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\alpha_0\\\\\n",
    "\\alpha_1\\\\\n",
    "\\vdots\\\\\n",
    "\\alpha_n\\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "\\int_a^b 1 dx = b-a\\\\\n",
    "\\int_a^b x dx =  \\frac{b^2-a^2}{2}\\\\\n",
    "\\vdots\\\\\n",
    "\\int_a^b x^n dx =  \\frac{b^{n+1}-a^{n+1}}{n+1}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "De hecho, si aplicamos esto para grados 0, 1 y 2, obtenemos los $\\alpha_i$ de los casos de extremo izquierdo ($\\alpha_0 = 1$), trapecios ($\\alpha_0 = \\alpha_1 = 1/2$) y Simpson ($\\alpha_0 = \\alpha_2 = 1/6$, $\\alpha_2 = 2/3$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formulas_newton_cotes(f, orden=1, x_vals=None,  y_vals=None, I=[0, 1], var=symbols('x')):\n",
    "    ff = Function('f')\n",
    "    \n",
    "    if x_vals is None:\n",
    "        x_vals = np.linspace(I[0], I[1], orden + 1)\n",
    "    if y_vals is None:\n",
    "        y_vals = [f.subs(var, i) for i in x_vals]\n",
    "    \n",
    "    G = ones(len(x_vals), len(x_vals))\n",
    "    for row in range(1, len(x_vals)):\n",
    "        for col in range(len(x_vals)):\n",
    "            G[row, col] = x_vals[col] ** row\n",
    "    \n",
    "    x_mat = nsimplify(Matrix([(I[1] ** (i + 1) - I[0] ** (i + 1))/(i + 1) for i in range(len(x_vals))]), rational=True)\n",
    "\n",
    "    # Con esto creamos el vector de valores de A\n",
    "    a = nsimplify(matriz_inversa(G) * x_mat, rational=True)\n",
    "    \n",
    "    Q, val = S(0), S(0)\n",
    "    for i in range(len(x_vals)):\n",
    "        Q += a[i] * ff(nsimplify(x_vals[i], rational=True))\n",
    "        val += nsimplify(a[i] * f.subs(var, x_vals[i]), rational=True)\n",
    "    \n",
    "    return Q, val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EJERCICIO 63\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, val = formulas_newton_cotes(1/(1+x**2), orden=0, I=[-5, 5])\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, val = formulas_newton_cotes(1/(1+x**2), orden=1, I=[-5, 5])\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, val = formulas_newton_cotes(1/(1+x**2), orden=2, I=[-5, 5])\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, val = formulas_newton_cotes(1/(1+x**2), orden=3, I=[-5, 5])\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, val = formulas_newton_cotes(1/(1+x**2), orden=4, I=[-5, 5])\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 15):\n",
    "    Q, val = formulas_newton_cotes(1/(1+x**2), orden=i, I=[-5, 5])\n",
    "    print(i, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error de la fórmula de cuadratura del trapecio y de newton\n",
    "\n",
    "Para una aproximación de grado $n$, el error de aproximación viene definido por:\n",
    "$$e_n(f) = \\int_a^bf[a=x_0, x_1, x_2, \\cdots, x_n=b]\\omega_n(x)dx$$\n",
    "\n",
    "Para el caso del trapecio (grado 1) el error es: \n",
    "$$e_1(f) = \\frac{\\max_{\\eta \\in [a,b]} |f''(\\eta)|}{12}(b-a)^3$$\n",
    "\n",
    "Para el caso del trapecio (grado 2) el error es: \n",
    "$$e_2(f) = \\frac{\\max_{\\eta \\in [a,b]} |f^{(4)}(\\eta)|}{90}\\left(\\frac{b-a}{2}\\right)^5$$\n",
    "\n",
    "Para $\\eta \\in [a, b]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_trapecio(f, var=symbols('x'), I=[0,1]):\n",
    "    diff_f = f\n",
    "    for _ in range(2):\n",
    "        diff_f = diff_f.diff(var)\n",
    "        \n",
    "    max_diff_f = nsimplify(maximum(diff_f, var, Interval(I[0], I[1])), rational=True)\n",
    "                           \n",
    "    factor_division = (I[1] - I[0]) ** 3 / 12\n",
    "    \n",
    "    e = max_diff_f * factor_division   \n",
    "                           \n",
    "    return e, max_diff_f, factor_division        \n",
    "\n",
    "\n",
    "def error_simpson(f, var=symbols('x'), I=[0,1]):\n",
    "    diff_f = f\n",
    "    for _ in range(4):\n",
    "        diff_f = diff_f.diff(var)\n",
    "        \n",
    "    max_diff_f = nsimplify(maximum(diff_f, var, Interval(I[0], I[1])), rational=True)\n",
    "                           \n",
    "    factor_division = ((I[1] - I[0])/2) ** 5 / 90\n",
    "    \n",
    "    e = max_diff_f * factor_division   \n",
    "                           \n",
    "    return e, max_diff_f, factor_division  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e, max_diff, int_omega = error_trapecio(1/(1+x**2), I=[-5, 5])\n",
    "N(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e, max_diff, int_omega = error_cuadratura_integral(1/(1+x**2), x_vals=[-5, 5], I=[-5, 5])\n",
    "N(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e, max_diff, int_omega = error_simpson(1/(1+x**2), I=[-5, 5])\n",
    "N(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e, max_diff, int_omega = error_cuadratura_integral(1/(1+x**2), x_vals=[-5, 0, 5], I=[-5, 5])\n",
    "N(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuadratura compuesta\n",
    "\n",
    "Uno de los problemas clásicos de emplear los polinomios de cuadratura para aproximar las integrales es que, para funciones complejas, con máximos y mínimos, la aproximación deja de ser buena para grados altos. Cojamos por ejemplo, $f(x) = x + sin^2(x)$ en $x \\in [0, 2\\pi]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy.plotting import plot\n",
    "\n",
    "p1 = plot(1/(1+x**2), (x, -4, 4), ylim=[0,1], axis_center=(0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N(Integral(1/(1+x**2), (x, -4, 4)).doit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 15):\n",
    "    Q, val = formulas_newton_cotes(1/(1+x**2), orden=i, I=[-4, 4])\n",
    "    print(i, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los valores de la integral se van para $n$ altos. Esto tiene sentido en base a lo que hemos visto del fenómeno de Runge y las aproximaciones de grado alto de ciertas funciones, que resultan en polinomios que pueden interpolar bien, pero ser poco efectivos fuera de los nodos.\n",
    "\n",
    "Para evitar saltos del estilo, podemos calcular en vez de un polinomio de cuadratura en $[a,b]$, calcular $m$ polinomios en el intervalo de $[a,b]$ divido $m$ veces: $[a = x_0, x_1,\\cdots, x_{m-1}, x_m=b]$, donde $h = x_i - x_{i-1} = x_{i+1} - x_{i} = \\frac{b-a}{m}$. Así, por ejemplo, la cuadratura de trapecios compuesta resultaría en la fórmula:\n",
    "$$Q_{1,m}(f) = \\sum_{i = 0}^{m-1} \\frac{h}{2}(f(x_i) + f(x_{i+1})$$\n",
    "El error de la fórmula es el mismo que el de $Q_1$, solo que propagado a lo largo de $m$ intervalos:\n",
    "$$E_{1,m}(f) = - \\sum_{i = 0}^{m-1}\\frac{f''(\\eta_i)}{12}h^3$$\n",
    "Del teorema del valor intermedio podemos simplificar la expresión, teniendo en mente que existe un $\\eta \\in [a,b]$ tal que:\n",
    "$$E_{1,m}(f) = - \\frac{f''(\\eta)}{12}mh^3 = - \\frac{f''(\\eta)}{12}(b-a)h^2$$\n",
    "\n",
    "\n",
    "Para la cuadratura de Simpson se procede igual:\n",
    "$$Q_{2,m} = \\sum_{i = 0}^{m-1} \\frac{h}{6}(f(x_{2i}) + 4f(x_{2i+1}) + f(x_{2(i+1)}))$$\n",
    "Aqui el intervalo, aunque está dividido en $m$ partes, para calcular la cuadratura por intervalo, se subdivide en 2 partes, de ahí el $2m$.\n",
    "\n",
    "El error de la cuadratura de Simpson es:\n",
    "$$E_{2,m}(f) = - \\sum_{i = 0}^{m-1}\\frac{f^{(4)}(\\eta_i)}{90}\\left(\\frac{h}{2}\\right)^5  \\rightarrow - \\frac{f^{(4)}(\\eta)}{90}m\\left(\\frac{h}{2}\\right)^5 = \n",
    "- \\frac{f^{(4)}(\\eta)}{180}(b-a)\\left(\\frac{h}{2}\\right)^4$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formulas_newton_cotes_m(f, orden=1, m=10, I=[0, 1], var=symbols('x')):\n",
    "    lista_vals, lista_Q = [], []\n",
    "    lista_m = np.linspace(I[0], I[1], m + 1)\n",
    "    \n",
    "    for m_i in range(m):\n",
    "        m0, mf = lista_m[m_i], lista_m[m_i + 1]\n",
    "        Q, val = formulas_newton_cotes(f, orden=orden, I=[m0, mf], var=var)\n",
    "        lista_Q.append(Q)\n",
    "        lista_vals.append(val)\n",
    "    \n",
    "    Q = sum(lista_Q)\n",
    "    val = sum(lista_vals)\n",
    "    \n",
    "    return Q, val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EJEMPLO 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_12, val_12 = formulas_newton_cotes_m(f=x**4, orden=1, m=2, I=[0, 1], var=symbols('x'))\n",
    "Q_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_14, val_14 = formulas_newton_cotes_m(f=x**4, orden=1, m=4, I=[0, 1], var=symbols('x'))\n",
    "Q_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_22, val_22 = formulas_newton_cotes_m(f=x**4, orden=2, m=2, I=[0, 1], var=symbols('x'))\n",
    "Q_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_trapecio_m(f, var=symbols('x'), I=[0,1], m=2):\n",
    "    diff_f = f\n",
    "    for _ in range(2):\n",
    "        diff_f = diff_f.diff(var)\n",
    "        \n",
    "    max_diff_f = nsimplify(maximum(diff_f, var, Interval(I[0], I[1])), rational=True)\n",
    "                           \n",
    "    factor_division = (I[1] - I[0]) ** 3 / (12 * (m ** 2))\n",
    "    \n",
    "    e = max_diff_f * factor_division   \n",
    "                           \n",
    "    return e, max_diff_f, factor_division        \n",
    "\n",
    "\n",
    "def error_simpson_m(f, var=symbols('x'), I=[0,1], m=2):\n",
    "    diff_f = f\n",
    "    for _ in range(4):\n",
    "        diff_f = diff_f.diff(var)\n",
    "        \n",
    "    max_diff_f = nsimplify(maximum(diff_f, var, Interval(I[0], I[1])), rational=True)\n",
    "                           \n",
    "    factor_division = (I[1] - I[0]) ** 5 / (90 * (m ** 4) * (2 ** 5))\n",
    "    \n",
    "    e = max_diff_f * factor_division   \n",
    "                           \n",
    "    return e, max_diff_f, factor_division  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EJERCICIO 64\n",
    "Vamos a resolver el ejercicio iterativamente. Vamos a ver para qué $m$ conseguimos un error menor a 0.0001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e, max_diff_f, factor_division = error_trapecio_m(f, I=I, m=symbols('m'), var=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_univariate_inequality(e < 0.0001, symbols('m'), False, Interval(0, S.Infinity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 1/x\n",
    "I = [1, 3]\n",
    "\n",
    "for i in range(100, 120):\n",
    "    e, max_diff_f, factor_division = error_trapecio_m(f, I=I, m=i, var=x)\n",
    "    print(i, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos como para $m=116$ el error es menor a $10^{-4}$. Vamos a calcular el valor de $\\ln 3$ para ese $m$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, val = formulas_newton_cotes_m(f=1/x, orden=1, m=116, I=[1, 3], var=symbols('x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N(log(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EJERCICIO 65\n",
    "\n",
    "En este caso tenemos que hallar $m$ para resolver $\\int_0^1 e^xdx$ con una exactitud de $10^{-5}$. Como tenemos programado para $m$ en lugar de $h$, lo hacemos así."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, I = E ** x, [0, 1]\n",
    "\n",
    "e, max_diff_f, factor_division = error_simpson_m(f=f, I=I, m=symbols('m'), var=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N(solve_univariate_inequality(e < 0.00001, symbols('m'), False, Interval(0, S.Infinity)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que $m > 3.11$, luego $m = 4$, tal y como lo proponen en el ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, val = formulas_newton_cotes_m(f=f, orden=2, m=4, I=I, var=symbols('x'))\n",
    "N(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos el valor de la integral. Sabemos que $\\int_0^1 e^x = e |_0^1 = e - 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N(E - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fórmulas de Gauss\n",
    "Recordemos la resolución de cuadratura por la matriz de Vandermonde\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "1 & 1 & \\cdots & 1 \\\\\n",
    "x_0 & x_1 & \\cdots & x_n\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "x_0^n & x_1^n & \\cdots & x_n^n\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\alpha_0\\\\\n",
    "\\alpha_1\\\\\n",
    "\\vdots\\\\\n",
    "\\alpha_n\\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "\\int_a^b 1 dx = b-a\\\\\n",
    "\\int_a^b x dx =  \\frac{b^2-a^2}{2}\\\\\n",
    "\\vdots\\\\\n",
    "\\int_a^b x^n dx =  \\frac{b^{n+1}-a^{n+1}}{n+1}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "En este caso, estamos estableciendo los nodos de manera equidistante, o arbitrariamente. En el mismo sentido de la aproximación de los polinomios, a la hora de resolver la cuadratura podemos escoger los valores $x_i$ de manera que la resolución de la cuadratura sea mejor. En este caso, los polinomios que establecen son los de Chebyshev y los de Legendre. \n",
    "Por tanto, el proceso es el mismo que el de la cuadratura al uso, pero sustituyendo los valores de x por el de las raices del polinomio de Chebyshev/Legendre del grado deseado.\n",
    "\n",
    "Como los polinomios están descritos en el intervalo $[-1, 1]$, si tenemos un problema en un intervalo $I = [a,b]$ podemos hacer un cambio de variable a $[-1, 1]$, una vez obtenidas las variables para la cuadratura, revertir el cambio de variable. Este cambio de variable **también cambia el valor de $\\alpha$!!!**\n",
    "\n",
    "Si $x = \\frac{b-a}{2} t + \\frac{b+a}{2}$ tenemos que $$\\hat{\\alpha}_i = \\int_{a}^{b} \\hat{l}_i dx = \\int_{-1}^{1} l_i(t) dt = \\frac{b-a}{2} \\alpha_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formulas_gauss(f, I=[-1, 1], var=symbols('x'), grado=3, modo='legendre'):\n",
    "    ff = Function('f')\n",
    "\n",
    "    if modo=='legendre':\n",
    "        x_vals = sorted(solve(legendre(grado, var)))\n",
    "    elif modo=='chebyshev':\n",
    "        x_vals = sorted(solve(chebyshevt(grado, var)))\n",
    "    \n",
    "    G = ones(len(x_vals), len(x_vals))\n",
    "    for row in range(1, len(x_vals)):\n",
    "        for col in range(len(x_vals)):\n",
    "            G[row, col] = x_vals[col] ** row\n",
    "    \n",
    "    x_mat = nsimplify(Matrix([((1) ** (i + 1) - (-1) ** (i + 1))/(i + 1) for i in range(len(x_vals))]), rational=True)\n",
    "\n",
    "    # Con esto creamos el vector de valores de A\n",
    "    a = nsimplify((I[1] - I[0])/2 * (matriz_inversa(G) * x_mat), rational=True)\n",
    "    \n",
    "    # Aquí efectuamos el cambio de variable:\n",
    "    cambio_var = (I[1] - I[0])/2 * var + (I[1] + I[0])/2\n",
    "    Q, val = S(0), S(0)\n",
    "    for i in range(len(x_vals)):\n",
    "        Q += a[i] * ff( nsimplify(cambio_var.subs(var, x_vals[i]), rational=True))\n",
    "        val += nsimplify(a[i] * f.subs(var, cambio_var.subs(var, x_vals[i])), rational=True)\n",
    "        \n",
    "    return Q, val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EJERCICIO 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, val = formulas_gauss(f=E**(-x**2), I=[0.2, 1.5], var=symbols('x'), grado=3, modo='legendre')\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EJERCICIO 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x ** symbols('n')\n",
    "I = [-1, 1]\n",
    "\n",
    "Q_leg, val_leg = formulas_gauss(f=f, I=I, var=symbols('x'), grado=2, modo='legendre')\n",
    "Q_leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_chev, val_chev = formulas_gauss(f=f, I=I, var=symbols('x'), grado=2, modo='chebyshev')\n",
    "Q_chev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_chev"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "ANMI.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
